{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad062b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1faf6d2",
   "metadata": {},
   "source": [
    "# 1.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb169b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, stopwords, debug=True):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        if debug:\n",
    "            df = df.sample(2000).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.sample(50000).reset_index(drop=True)\n",
    "        # 读取常用停用词\n",
    "        counter = Counter()\n",
    "        sentences = []\n",
    "        for title in tqdm(df['title']):   \n",
    "            # 去除标点符号\n",
    "            title = re.sub(r'[^\\u4e00-\\u9fa5]', '', title)\n",
    "            tokens = [token for token in tokenizer(title.strip()) if token not in stopwords]\n",
    "            counter.update(tokens)\n",
    "            sentences.append(tokens)\n",
    "        self.vocab = torchtext.vocab.vocab(counter, specials=['<unk>', '<pad>'])\n",
    "        \n",
    "        # 构造输入和输出，跳元模型，用当前字预测前一个字和后一个字\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        for sen in sentences:\n",
    "            for i in range(1, len(sen) - 1):\n",
    "                self.inputs.append([self.vocab[sen[i]]])\n",
    "                self.labels.append([self.vocab[sen[i - 1]]])\n",
    "                self.inputs.append([self.vocab[sen[i]]])\n",
    "                self.labels.append([self.vocab[sen[i + 1]]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.inputs[idx]), torch.LongTensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fa1387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557923855b1469f96c11583a50a7691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../data/THUCNews/train.csv'\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('spacy', language='zh_core_web_sm')\n",
    "stopwords = [line.strip() for line in open('../stopwords/cn_stopwords.txt', 'r', encoding='utf-8').readlines()]\n",
    "dataset = MyDataset(file_path, tokenizer, stopwords)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4eb3e5",
   "metadata": {},
   "source": [
    "# 2.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d651b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        # W和WT的形状是转置的\n",
    "        self.W = nn.Embedding(vocab_size, embed_size)  # vocab_size -> embed_size\n",
    "        self.WT = nn.Linear(embed_size, vocab_size, bias=False)  # embed_size -> vocab_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X形状：batch_size * vocab_size\n",
    "        hidden_layer = self.W(X)\n",
    "        output_layer = self.WT(hidden_layer)\n",
    "        return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71631957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(\n",
      "  (W): Embedding(8456, 512)\n",
      "  (WT): Linear(in_features=512, out_features=8456, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = Word2Vec(vocab_size=len(dataset.vocab), embed_size=512)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 查看模型\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f7c0d",
   "metadata": {},
   "source": [
    "# 3.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edadaac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss = 8.912559\n",
      "epoch: 2 loss = 6.400843\n",
      "epoch: 3 loss = 5.419957\n",
      "epoch: 4 loss = 4.417579\n",
      "epoch: 5 loss = 4.015151\n",
      "epoch: 6 loss = 3.830552\n",
      "epoch: 7 loss = 3.863740\n",
      "epoch: 8 loss = 3.856899\n",
      "epoch: 9 loss = 3.621994\n",
      "epoch: 10 loss = 3.606398\n",
      "epoch: 11 loss = 3.689243\n",
      "epoch: 12 loss = 3.309719\n",
      "epoch: 13 loss = 3.388777\n",
      "epoch: 14 loss = 3.631728\n",
      "epoch: 15 loss = 3.625928\n",
      "epoch: 16 loss = 3.460016\n",
      "epoch: 17 loss = 3.599987\n",
      "epoch: 18 loss = 3.469801\n",
      "epoch: 19 loss = 3.327806\n",
      "epoch: 20 loss = 3.369408\n"
     ]
    }
   ],
   "source": [
    "# 训练20个epoch\n",
    "for epoch in range(20):\n",
    "    for train_input, train_label in dataloader:\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output.squeeze_(), train_label.squeeze_())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch:', epoch + 1, 'loss =', '{:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2426e0d",
   "metadata": {},
   "source": [
    "# 4.查看模型参数（vector）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee9ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, WT = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a55f9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8456, 512]) torch.Size([8456, 512])\n"
     ]
    }
   ],
   "source": [
    "# W对应vocab中每个词的vector，这里是512维\n",
    "print(W.shape, WT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d630e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.2287e-01,  1.7147e+00,  6.3301e-02, -8.2303e-01,  2.6472e-04,\n",
      "        -8.6783e-01,  7.7127e-01, -7.2511e-02, -7.2578e-02, -7.4657e-01,\n",
      "         3.7388e-01,  2.5191e-01, -7.3627e-01, -1.6520e+00, -5.1887e-01,\n",
      "         1.0842e+00,  7.9234e-01,  2.3700e-01,  5.0631e-01,  1.6158e+00,\n",
      "         1.3460e+00, -5.6373e-01, -1.3444e+00, -1.4603e-03,  2.8087e-02,\n",
      "         7.8602e-01, -7.2021e-01,  1.3479e+00, -7.6845e-01,  1.3702e+00,\n",
      "        -3.0853e-02, -5.1576e-01,  9.2350e-01, -1.4483e+00,  3.8712e-02,\n",
      "        -2.7035e-01,  1.2906e+00, -3.3333e-01, -1.1882e-02, -6.2058e-01,\n",
      "        -1.3944e+00, -1.1244e-01, -4.3255e-01, -2.8653e+00,  1.7908e+00,\n",
      "        -3.3256e-01,  1.4750e+00,  4.1109e-01,  7.2152e-01,  8.5703e-02,\n",
      "        -1.3381e+00,  1.3475e-01,  6.8010e-01,  5.6846e-01,  3.7432e-01,\n",
      "        -5.4027e-01,  9.2805e-02, -4.3790e-01, -8.1059e-01,  2.2791e-01,\n",
      "         7.0500e-01,  6.0567e-01,  5.0068e-01, -3.4578e-02, -4.5616e-01,\n",
      "         1.3117e+00, -3.9012e-01,  7.3155e-01,  1.9467e+00, -1.2233e-01,\n",
      "        -9.1838e-01, -4.6565e-01,  4.5994e-01,  6.8919e-01, -7.6768e-01,\n",
      "         1.7048e+00,  1.5130e-01,  5.8529e-01,  8.9172e-01, -8.3112e-01,\n",
      "         1.2281e+00, -1.6852e+00,  7.6857e-01, -8.8572e-01, -1.9871e+00,\n",
      "         2.9811e-02, -1.0785e+00,  8.1088e-01, -2.7514e-01,  3.7859e-01,\n",
      "         7.1724e-01, -7.7252e-01,  7.3603e-01,  8.4712e-01, -1.2583e-01,\n",
      "        -7.9981e-01,  1.5318e-01, -2.5004e-01,  6.7352e-01,  6.0100e-01,\n",
      "        -6.4240e-01, -1.1211e+00, -3.6981e-01,  5.1754e-01,  1.9530e+00,\n",
      "        -6.5116e-01, -6.5747e-01, -1.7379e-01, -1.2033e+00, -5.4489e-01,\n",
      "        -1.2881e+00, -7.1152e-01,  1.1986e+00,  8.9261e-01, -8.7649e-01,\n",
      "        -1.5737e+00, -2.3979e+00, -1.0635e+00,  1.9157e+00,  4.4747e-01,\n",
      "         9.8586e-01, -1.2429e+00, -1.4884e+00, -6.0112e-01, -1.7173e+00,\n",
      "         9.0132e-01,  1.1632e+00,  1.0525e+00,  1.1039e-01,  1.3915e-01,\n",
      "         1.2256e+00, -7.6839e-02, -4.2135e-01,  1.1138e+00, -4.5362e-02,\n",
      "        -1.2519e+00,  5.6123e-02,  8.8503e-01,  1.3936e+00, -2.6982e-01,\n",
      "        -9.0809e-01,  6.0159e-01,  1.3851e+00, -8.2730e-01,  9.1948e-02,\n",
      "         6.6886e-02,  1.4601e-02,  5.4289e-01,  9.4249e-01,  1.3909e+00,\n",
      "         1.1468e+00, -2.9593e-01,  2.0872e+00, -1.1757e+00, -1.0830e+00,\n",
      "        -9.7404e-01, -1.5314e+00,  1.2158e+00, -1.2181e+00,  2.0501e+00,\n",
      "        -5.2641e-01, -7.1079e-01, -2.1443e+00, -7.3788e-01, -1.4088e+00,\n",
      "        -1.0341e+00,  2.0926e-01, -1.7982e+00,  3.5203e-01,  1.1599e-01,\n",
      "        -8.3653e-01, -3.5964e-02, -5.8308e-01,  1.7954e-01, -8.7481e-01,\n",
      "         1.0098e+00,  5.5540e-01, -3.2201e-01,  7.0473e-01, -7.5013e-01,\n",
      "         3.4308e-01,  2.9481e+00,  8.8922e-01, -2.3844e-01,  6.2528e-01,\n",
      "        -1.1791e+00,  4.3488e-01, -6.4063e-01,  9.3774e-02,  1.0300e+00,\n",
      "        -4.1556e-01, -1.4286e+00, -7.2680e-01, -5.3921e-01,  1.4146e-01,\n",
      "         2.0545e+00,  2.9175e-01,  1.6318e+00,  2.4756e-01,  1.2724e+00,\n",
      "         5.8133e-01, -1.4831e+00, -1.0041e+00,  1.9385e+00,  1.9325e-01,\n",
      "         1.2200e+00, -1.4117e+00,  3.9271e-02,  4.5508e-01,  1.4718e+00,\n",
      "        -7.4412e-01, -4.7352e-01,  1.3905e+00,  1.0859e+00,  7.5518e-01,\n",
      "        -4.1263e-01,  7.2290e-01, -7.3637e-01, -7.6164e-01,  3.3811e-01,\n",
      "         3.7533e-01,  1.2606e+00, -2.3075e-01,  4.4719e-01, -3.2363e-01,\n",
      "        -2.7149e-01, -6.3052e-03, -3.5280e-01,  1.7745e+00, -6.7188e-01,\n",
      "        -6.6865e-01, -1.7804e-02, -5.5077e-01,  5.2927e-02, -3.7623e-01,\n",
      "        -1.7041e-01, -6.6628e-01, -7.5262e-01,  1.3980e+00,  2.3167e-01,\n",
      "         1.0042e+00,  1.3869e+00, -2.8267e-01, -3.0873e-01,  2.0073e+00,\n",
      "         5.5964e-01,  7.3455e-01, -1.1055e+00,  1.6308e+00, -1.4819e-01,\n",
      "         9.9809e-01,  2.1353e+00, -3.1568e-01,  5.8801e-01,  9.2924e-01,\n",
      "         9.7401e-02, -1.2094e-01,  2.7261e+00, -7.8181e-01,  9.0020e-01,\n",
      "        -1.7918e+00, -1.1279e-01,  9.7616e-01, -1.2426e+00,  5.7910e-01,\n",
      "        -1.1188e+00,  2.0179e+00,  1.4198e+00,  4.9230e-01,  1.2504e+00,\n",
      "         1.0734e+00,  3.5667e-02,  1.3575e+00,  8.9911e-01,  2.2027e-01,\n",
      "        -6.4312e-01,  1.4937e-01,  2.6781e-01, -1.2156e+00, -3.0388e+00,\n",
      "        -2.1999e-01,  6.2441e-01, -9.3184e-02,  1.1808e+00,  2.2401e-01,\n",
      "         3.9966e-01, -1.1190e+00, -8.3389e-01, -5.9261e-01,  8.6697e-02,\n",
      "        -5.3306e-01,  1.8315e+00, -3.8333e-01, -5.5937e-01, -7.8289e-01,\n",
      "        -2.2317e+00, -4.1092e-01, -1.4492e+00, -1.3280e+00,  2.0675e+00,\n",
      "        -7.3146e-01, -1.6172e+00, -2.1627e-01,  8.0208e-01, -2.0851e+00,\n",
      "        -1.2495e-01,  6.1523e-02,  1.5019e+00,  5.3290e-01,  1.1912e+00,\n",
      "        -1.2201e+00,  1.7694e-01, -7.3861e-02, -9.2096e-02,  4.0679e-03,\n",
      "        -4.4099e-01,  1.3067e-01,  1.3890e+00,  5.5755e-01,  1.2668e-01,\n",
      "        -5.4407e-01,  9.9933e-01, -6.4629e-01,  1.0877e-01, -1.6786e+00,\n",
      "        -1.3094e+00, -1.4667e-01, -3.0712e-02, -1.5379e+00,  1.4222e+00,\n",
      "        -4.1159e-01, -1.3730e-01,  8.0257e-01,  1.1333e+00, -1.0141e+00,\n",
      "         1.7227e+00, -5.0936e-01,  1.3076e+00, -1.5861e+00,  9.9355e-01,\n",
      "        -5.0454e-02,  5.0314e-01,  4.2356e-01,  1.0131e-01, -6.5947e-01,\n",
      "        -4.1998e-01, -2.1922e-01, -1.1955e+00,  1.4833e-01,  1.1458e+00,\n",
      "        -1.2556e+00,  2.1008e+00, -1.2783e+00,  7.8290e-01, -9.6071e-01,\n",
      "         8.0150e-02, -3.8382e-01,  2.6563e-02, -1.2764e-01, -7.0741e-01,\n",
      "        -7.9743e-01, -9.5904e-01, -1.2110e-01, -5.8977e-03,  4.1408e-01,\n",
      "        -1.9486e+00,  9.3227e-01,  6.3597e-01, -1.7498e-01, -2.0754e-01,\n",
      "         1.5076e-01, -5.2064e-01,  2.1350e+00, -3.2217e-01, -1.0778e+00,\n",
      "        -2.8783e-01,  3.2381e-01,  6.0525e-01,  4.1591e-03, -8.6110e-01,\n",
      "         2.3192e-01,  6.5962e-01, -1.4417e+00,  7.1068e-01,  6.5148e-01,\n",
      "        -6.5773e-01, -4.1840e-02, -6.7818e-01, -6.5538e-01,  1.1979e+00,\n",
      "        -1.8252e-03, -1.6705e-01, -1.4741e+00, -2.7066e-02, -1.5744e+00,\n",
      "        -1.2761e+00, -1.7351e+00,  7.5307e-01,  5.2161e-01,  8.0946e-01,\n",
      "        -2.9692e-02,  3.7937e-01, -3.2278e-01,  5.8241e-01,  9.5021e-02,\n",
      "         1.3459e+00, -4.0619e-01,  7.0984e-01, -6.1239e-01, -4.6134e-01,\n",
      "         1.0800e+00, -5.2282e-01,  5.3710e-01, -4.4650e-01, -7.1281e-03,\n",
      "        -5.1894e-01,  8.2832e-01, -1.6451e+00, -2.9573e-01, -3.6383e-01,\n",
      "        -7.0615e-01,  2.1297e-01,  3.8449e-01, -1.1305e+00,  5.7326e-01,\n",
      "         9.9624e-01, -1.6119e-01,  5.3302e-01, -5.4278e-01,  2.7801e-01,\n",
      "        -1.9126e+00,  1.6354e-01,  6.8131e-02,  1.0922e+00, -1.1702e+00,\n",
      "         2.0472e+00, -6.7316e-01,  2.2030e-01,  9.0615e-01,  5.7489e-01,\n",
      "         7.9106e-02,  9.2267e-01, -3.9565e-01, -8.8711e-01,  2.4204e-01,\n",
      "        -1.7568e-01,  3.2551e-01,  1.0685e+00, -4.8625e-02, -1.3912e+00,\n",
      "        -1.2846e+00, -5.3165e-01, -7.1330e-01,  8.4463e-01,  1.0784e-01,\n",
      "         1.4889e+00,  9.8450e-01, -6.5920e-01,  2.0449e+00,  4.1551e-01,\n",
      "        -1.1835e+00,  1.0958e+00,  9.2653e-01, -1.3768e+00,  1.8171e+00,\n",
      "        -3.2302e-01, -2.5711e-01, -1.5041e+00,  2.4013e+00, -6.8337e-01,\n",
      "        -1.3515e-01,  1.1649e+00, -2.0898e+00, -4.9819e-01, -1.1672e+00,\n",
      "        -3.1093e-01, -8.0316e-01, -3.4353e-01,  1.0687e+00,  1.9046e+00,\n",
      "         3.7529e-01,  2.3937e-01, -8.2549e-01, -1.5946e+00,  4.4685e-01,\n",
      "         1.0898e-02, -4.7331e-01, -5.6478e-02, -4.4632e-01,  1.5692e+00,\n",
      "        -4.0129e-01,  7.7716e-01, -3.2211e-01,  1.2220e+00, -1.4119e+00,\n",
      "        -2.1803e-01, -5.3301e-01,  1.7802e-01, -1.1321e+00, -1.8399e+00,\n",
      "        -1.4802e+00,  1.1821e+00, -4.5132e-01, -1.6545e+00,  8.0576e-01,\n",
      "         1.0221e+00, -1.5706e+00,  9.2200e-01, -1.2866e+00, -1.0188e+00,\n",
      "        -4.1352e-02, -3.0925e-01], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2e48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
