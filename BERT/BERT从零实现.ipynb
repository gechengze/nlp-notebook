{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b894dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9e8e7",
   "metadata": {},
   "source": [
    "### BERT输入数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6062816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDateset(Dataset):\n",
    "    def __init__(self, tokenizer, dateset_path, dateset_type='train', num_sample=1000, max_len=128):\n",
    "        super(MyDateset, self).__init__()\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dateset_path, dateset_type + '.csv')).sample(num_sample)\n",
    "\n",
    "        paragraphs = []\n",
    "        for c, f in zip(df['class'], df['file']):\n",
    "            with open(os.path.join(dateset_path, c, f)) as file:\n",
    "                paragraphs.append([sentence for paragraph in file.readlines()\n",
    "                                   for sentence in paragraph.split('。') if sentence.strip()])\n",
    "\n",
    "        self.examples = []\n",
    "\n",
    "        for paragraph in tqdm(paragraphs):\n",
    "            for i in range(len(paragraph) - 1):\n",
    "                sentence_a = paragraph[i]\n",
    "                # 50%的概率将连续两个句子拼接在一起，50%概率将不相邻的两个句子拼接在一起\n",
    "                if random.random() < 0.5:\n",
    "                    is_next = 1\n",
    "                    sentence_b = paragraph[i + 1]\n",
    "                else:\n",
    "                    sentence_b = random.choice(random.choice(paragraphs))\n",
    "                    is_next = 0\n",
    "\n",
    "                # 将两个句子进行编码\n",
    "                encoded = tokenizer.encode_plus(sentence_a, sentence_b,\n",
    "                                                max_length=max_len, padding='max_length')\n",
    "\n",
    "                # 如果两个句子拼起来超过最大长度，则跳过\n",
    "                if len(encoded['input_ids']) > self.max_len:\n",
    "                    continue\n",
    "\n",
    "                encoded['is_next'] = is_next  # 是否相邻句子标识\n",
    "                encoded = self.get_mlm_data(encoded)  # 进行掩码操作\n",
    "                self.examples.append(encoded)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.LongTensor(self.examples[idx].input_ids),\n",
    "            torch.LongTensor(self.examples[idx].token_type_ids),\n",
    "            torch.LongTensor(self.examples[idx].attention_mask),\n",
    "            torch.LongTensor([self.examples[idx].is_next]),\n",
    "            torch.LongTensor(self.examples[idx].pred_positions),\n",
    "            torch.LongTensor(self.examples[idx].pred_labels)\n",
    "        )\n",
    "\n",
    "    def get_mlm_data(self, encoded):\n",
    "        candidate_pred_positions = []  # 除去特殊token外的所有token的位置\n",
    "        for i, token in enumerate(encoded['input_ids']):\n",
    "            # <CLS> <SEP> <PAD> 这三个token不做预测\n",
    "            if token in [self.tokenizer.cls_token_id,\n",
    "                         self.tokenizer.sep_token_id,\n",
    "                         self.tokenizer.pad_token_id]:\n",
    "                continue\n",
    "            candidate_pred_positions.append(i)\n",
    "\n",
    "        # 随机替换15%的token为<MASK>\n",
    "        num_mlm_preds = max(1, round(sum(encoded['attention_mask']) * 0.15))\n",
    "\n",
    "        # 要预测的token的位置\n",
    "        pred_positions = sorted(random.sample(candidate_pred_positions, num_mlm_preds))\n",
    "\n",
    "        # 要预测的token的真实值\n",
    "        pred_labels = [encoded['input_ids'][pos] for pos in pred_positions]\n",
    "\n",
    "        for pos in pred_positions:\n",
    "            if random.random() < 0.8:\n",
    "                # 80%的概率将token替换为<MASK>\n",
    "                encoded['input_ids'][pos] = tokenizer.mask_token_id\n",
    "            else:\n",
    "\n",
    "                if random.random() < 0.5:\n",
    "                    # 10%的概率token不变\n",
    "                    continue\n",
    "                else:\n",
    "                    # 10%的概率随机替换成另外一个token\n",
    "                    encoded['input_ids'][pos] = random.choice(range(106, tokenizer.vocab_size))\n",
    "\n",
    "        # 将要预测的token位置和真实值pad到max_len * 0.15的长度，方便批量计算\n",
    "        max_num_mlm_preds = round(self.max_len * 0.15)\n",
    "        pred_positions += [0] * (max_num_mlm_preds - num_mlm_preds)\n",
    "        pred_labels += [0] * (max_num_mlm_preds - num_mlm_preds)\n",
    "\n",
    "        encoded['pred_positions'] = pred_positions\n",
    "        encoded['pred_labels'] = pred_labels\n",
    "\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fd458",
   "metadata": {},
   "source": [
    "### BERT模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7bee3f",
   "metadata": {},
   "source": [
    "#### Embdding层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59502448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, hidden_size):\n",
    "        super(Embedding, self).__init__()\n",
    "        # token embedding\n",
    "        self.tok_embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        # 两个句子的embedding\n",
    "        self.seg_embed = nn.Embedding(2, hidden_size)\n",
    "        # 位置embedding\n",
    "        self.pos_embed = nn.Embedding(max_len, hidden_size)\n",
    "        # 层归一化\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        # x输入：批量大小 * 步长\n",
    "        seq_len = x.shape[1]\n",
    "        # 位置编码，扩展维度后和x输入一样，批量大小 * 步长\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).unsqueeze(0).expand_as(x)\n",
    "        # 三个embedding相加\n",
    "        embedded = self.tok_embed(x) + self.seg_embed(seg) + self.pos_embed(pos)\n",
    "        return self.norm(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6234bb2",
   "metadata": {},
   "source": [
    "#### 注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29500ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缩放点积注意力\n",
    "class ScaledDotProductionAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductionAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask):\n",
    "        # query/key/value：批量大小 * 头数 * 步长 * 向量维度\n",
    "        # attn_mask尺寸：批量大小 * 头数 * 步长 * 步长\n",
    "        d_k = key.shape[-1]  # key的维度\n",
    "        # Q * K转置 / 根号d_k，scores尺寸：批量大小 * 头数 * 步长 * 步长\n",
    "        scores = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        attn_weights = self.softmax(scores)\n",
    "        return torch.matmul(attn_weights, value)  # 返回的结果尺寸：批量大小 * 头数 * 步长 * 向量维度\n",
    "\n",
    "\n",
    "# 多头注意力\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size  # 输入和输出的维度\n",
    "        self.num_heads = num_heads  # 头数\n",
    "        self.key_size = self.value_size = self.hidden_size // self.num_heads  # 输入输出维度必须可以整除头数，方便并行\n",
    "        self.attention = ScaledDotProductionAttention()  # 缩放点积注意力\n",
    "        self.W_Q = nn.Linear(hidden_size, hidden_size)  # Q的投影参数\n",
    "        self.W_K = nn.Linear(hidden_size, hidden_size)  # K的投影参数\n",
    "        self.W_V = nn.Linear(hidden_size, hidden_size)  # V的投影参数\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)  # 全连接层，多头分开做自注意力后，再拼接起来，接一个全连接层\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask):\n",
    "        # Q K V输入尺寸：批量大小 * 步长 * 维度\n",
    "        # mask输入尺寸：批量大小 * 步长 * 步长\n",
    "        batch_size = query.shape[0]\n",
    "        seq_len = query.shape[1]\n",
    "\n",
    "        # 方便多头并行计算，QKV投影后reshape成 批量大小 * 步长 * 头数 * 维度，再交换1、2维度，变成 批量大小 * 头数 * 步长 * 维度\n",
    "        q_s = self.W_Q(query).reshape(batch_size, -1, self.num_heads, self.key_size).transpose(1, 2)\n",
    "        k_s = self.W_Q(key).reshape(batch_size, -1, self.num_heads, self.key_size).transpose(1, 2)\n",
    "        v_s = self.W_Q(value).reshape(batch_size, -1, self.num_heads, self.value_size).transpose(1, 2)\n",
    "\n",
    "        # mask处理成 批量大小 * 头数 * 步长 * 步长\n",
    "        attn_mask = attn_mask.data.eq(0).unsqueeze(1).expand(batch_size, seq_len, seq_len)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)\n",
    "        # context尺寸：批量大小 * 头数 * 步长 * 单个头的维度\n",
    "        context = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "\n",
    "        # context尺寸：批量大小 * 步长 * hidden_size\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, self.hidden_size)\n",
    "\n",
    "        output = self.fc(context)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a7445",
   "metadata": {},
   "source": [
    "#### 前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c5cc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, hidden_size, ffn_size):\n",
    "        # 两个全连接层，使用gelu作为激活函数\n",
    "        super(PositionWiseFFN, self).__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, ffn_size)\n",
    "        self.fc2 = nn.Linear(ffn_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c11d2",
   "metadata": {},
   "source": [
    "#### 残差连接和层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d253c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        # 层归一化 + 残差连接\n",
    "        super(AddNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(norm_shape)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.layer_norm(x + self.dropout(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d2b5f",
   "metadata": {},
   "source": [
    "#### Transformer Encoder块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e9e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads, hidden_size, ffn_size, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(hidden_size=hidden_size, num_heads=num_heads)\n",
    "        self.add_norm1 = AddNorm(norm_shape=hidden_size, dropout=dropout)\n",
    "        self.ffn = PositionWiseFFN(hidden_size=hidden_size, ffn_size=ffn_size)\n",
    "        self.add_norm2 = AddNorm(norm_shape=hidden_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, attn_mask):\n",
    "        output = self.add_norm1(x, self.attention(x, x, x, attn_mask))\n",
    "        output = self.add_norm2(output, self.ffn(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6de258",
   "metadata": {},
   "source": [
    "#### BERT模型，是否相邻句子+MASK位置预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ba072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, num_layers, num_heads, vocab_size, max_len, hidden_size, ffn_size, dropout):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        self.embedding = Embedding(vocab_size=vocab_size, max_len=max_len, hidden_size=hidden_size)\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            self.layers.add_module(f'{i}', EncoderBlock(num_heads=num_heads, hidden_size=hidden_size,\n",
    "                                                        ffn_size=ffn_size, dropout=dropout))\n",
    "\n",
    "        # 是否下一个句子预测\n",
    "        self.is_next_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "\n",
    "        # 预测mask掉的token\n",
    "        self.mask_lm = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, vocab_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, attn_mask, pred_positions):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, attn_mask)\n",
    "\n",
    "        # 用输出的第一个位置，即[CLS]的768维的向量表示，拿来做是否是相邻句子的预测\n",
    "        cls_output = output[:, 0]\n",
    "        logit_is_next = self.is_next_classifier(cls_output)\n",
    "\n",
    "        # [MASK]位置的预测\n",
    "        batch_size, num_pred_positions = pred_positions.shape\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "        mask_output = output[batch_idx, pred_positions]\n",
    "        mask_output = mask_output.reshape((batch_size, num_pred_positions, -1))\n",
    "        logit_mask = self.mask_lm(mask_output)\n",
    "        return logit_is_next, logit_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e1d6f",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d46b50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('../../models/bert-base-chinese/')\n",
    "\n",
    "batch_size = 16\n",
    "num_layers = 12\n",
    "num_heads = 12\n",
    "vocab_size = tokenizer.vocab_size\n",
    "max_len = 128\n",
    "hidden_size = 768\n",
    "ffn_size = 768\n",
    "dropout = 0.5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1a6c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a79edaeeed437b96e6e7f575fbd93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dateset_path = '../../datasets/THUCNews'\n",
    "dataset_type = 'train'\n",
    "\n",
    "train_dataset = MyDateset(tokenizer, dateset_path, dataset_type, num_sample=100)\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b0b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.690628051757812\n",
      "9.60173511505127\n",
      "8.112561225891113\n",
      "10.450347900390625\n",
      "7.241786956787109\n",
      "8.32939624786377\n",
      "6.414041519165039\n",
      "7.8192644119262695\n",
      "7.597033977508545\n",
      "6.325974941253662\n",
      "6.770308494567871\n",
      "5.986588001251221\n",
      "6.670901298522949\n",
      "5.396482467651367\n",
      "5.837645530700684\n",
      "6.379173278808594\n",
      "5.863475322723389\n",
      "5.215243816375732\n",
      "5.913568019866943\n",
      "5.513426303863525\n",
      "4.987275123596191\n",
      "6.045734405517578\n",
      "6.13618278503418\n",
      "5.658156871795654\n",
      "5.895814418792725\n",
      "5.457124710083008\n",
      "5.517416954040527\n",
      "6.162562370300293\n",
      "5.552859306335449\n",
      "6.140622138977051\n",
      "5.651712894439697\n",
      "5.387009620666504\n",
      "5.55987024307251\n",
      "5.370710372924805\n",
      "5.786153316497803\n",
      "5.627994060516357\n",
      "5.651434898376465\n",
      "6.275754451751709\n",
      "6.109375953674316\n",
      "6.134186267852783\n",
      "5.125851631164551\n",
      "5.978160381317139\n",
      "5.583320140838623\n",
      "4.995095252990723\n",
      "5.838615417480469\n",
      "5.192169189453125\n",
      "6.618166446685791\n",
      "5.522721290588379\n",
      "5.575329780578613\n",
      "5.838029384613037\n",
      "5.690584182739258\n",
      "5.881687164306641\n",
      "6.0125346183776855\n",
      "5.405154705047607\n",
      "4.925724506378174\n",
      "5.6496901512146\n",
      "5.923046588897705\n",
      "6.4235711097717285\n",
      "5.2331366539001465\n",
      "6.694015979766846\n",
      "5.478486061096191\n",
      "5.10726261138916\n",
      "4.7596354484558105\n",
      "5.66757345199585\n",
      "5.735708713531494\n",
      "5.571993827819824\n",
      "5.963484764099121\n",
      "5.170076847076416\n",
      "5.514690399169922\n",
      "5.8447089195251465\n",
      "5.239368915557861\n",
      "5.833641529083252\n",
      "5.641147136688232\n",
      "5.690825939178467\n",
      "5.940491676330566\n",
      "5.341466903686523\n",
      "5.345152854919434\n",
      "6.1147565841674805\n",
      "5.45314884185791\n",
      "6.10474157333374\n",
      "5.162100791931152\n",
      "5.065823078155518\n",
      "5.585881233215332\n",
      "5.664594650268555\n",
      "4.811995506286621\n",
      "5.650722026824951\n",
      "6.0288166999816895\n",
      "5.780966758728027\n",
      "4.906027793884277\n",
      "5.141520977020264\n",
      "5.915700435638428\n",
      "5.97650146484375\n",
      "5.210946559906006\n",
      "5.912126541137695\n",
      "5.811132907867432\n",
      "5.575035095214844\n",
      "5.2475385665893555\n",
      "5.632976055145264\n",
      "5.80082893371582\n",
      "5.478268623352051\n",
      "5.372023105621338\n",
      "5.610230922698975\n",
      "5.342360019683838\n",
      "5.030355453491211\n",
      "4.673643112182617\n",
      "5.980657577514648\n",
      "5.499138832092285\n",
      "5.0563812255859375\n",
      "5.30993127822876\n",
      "5.154613494873047\n",
      "5.500649452209473\n",
      "5.907428741455078\n",
      "5.8321685791015625\n",
      "6.736120700836182\n",
      "5.277111530303955\n",
      "4.818557262420654\n",
      "5.967822551727295\n",
      "6.084552764892578\n",
      "5.486641883850098\n",
      "5.4454498291015625\n",
      "5.315744876861572\n",
      "4.755275726318359\n"
     ]
    }
   ],
   "source": [
    "model = BERT(num_layers=num_layers, num_heads=num_heads, vocab_size=vocab_size,\n",
    "             max_len=max_len, hidden_size=hidden_size, ffn_size=ffn_size, dropout=dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for input_ids, segment_ids, attn_mask, is_next, pred_positions, pred_labels in data_loader:\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "    is_next = is_next.to(device)\n",
    "    pred_positions = pred_positions.to(device)\n",
    "    pred_labels = pred_labels.to(device)\n",
    "\n",
    "    logit_is_next, logit_mask = model(input_ids, segment_ids, attn_mask, pred_positions)\n",
    "\n",
    "    loss_is_next = criterion(logit_is_next, is_next.view(-1))\n",
    "\n",
    "    loss_mask = criterion(logit_mask.view(-1, vocab_size), pred_labels.view(-1))\n",
    "\n",
    "    loss = loss_is_next + loss_mask\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db82fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
