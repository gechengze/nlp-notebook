{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679a2e1",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset_path, tokenizer):\n",
    "        df = pd.read_csv(dataset_path).dropna().sample(100_000).reset_index(drop=True)\n",
    "        self.labels = df['label']\n",
    "        self.n_classes = len(df['label'].unique())\n",
    "        self.texts = [tokenizer(title, padding='max_length', max_length=32, return_tensors='pt')\n",
    "                      for title in tqdm(df['title'])]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], np.array(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa98dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练模型 bert-base-chinese\n",
    "model_path = '/Users/gechengze/project/models/bert-base-chinese/'\n",
    "# bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 构造train dataloader和valid dataloader\n",
    "train_dataset = MyDataset('../data/THUCNews/train.csv', tokenizer)\n",
    "\n",
    "valid_dataset = MyDataset('../data/THUCNews/valid.csv', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80dc3e9",
   "metadata": {},
   "source": [
    "# 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_path)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input_ids, atention_mask):\n",
    "        _, pooled_output = self.bert(input_ids, atention_mask, return_dict=False)\n",
    "        output = self.dropout(pooled_output)\n",
    "        output = self.linear(output)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "model = BertClassifier(n_classes=train_dataset.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68050d51",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4157947",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "for train_input, train_label in train_dataloader:\n",
    "    input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "    attention_mask = train_input['attention_mask'].squeeze(1).to(device)\n",
    "    train_label = train_label.to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    loss = criterion(output, train_label)\n",
    "    acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(format(loss.item(), '.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f218771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
