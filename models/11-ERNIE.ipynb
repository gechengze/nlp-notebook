{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cca32ca",
   "metadata": {},
   "source": [
    "#### 相比于BERT\n",
    "改进1：Knowledge Integration，把MASK分成三部分\n",
    "- Basic-level Masking：与BERT一样；\n",
    "- Entity-level Masking：把实体作为一个整体[MASK]，例如 J.K.Rowling 这个词作为一个实体，被一起[MASK]；\n",
    "- Phrase-Level Masking：把短语作为一个整体[MASK]，如 a series of 作为一个短语整体，被一起[MASK]。\n",
    "\n",
    "改进2:Dialogue Language Model（DLM）\n",
    "- 数据不是单轮问答的形式（即问题+答案），而是多轮问答的数据，即可以是QQR、QRQ等等\n",
    "- 也就是Segment Embedding被Dialogue Embedding代替了，但其它结构跟MLM模型是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3769c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import ErnieModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34429d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../models/ernie-base-zh/ were not used when initializing ErnieModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = '../../models/ernie-base-zh/'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "model = ErnieModel.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d25a6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ErnieModel(\n",
       "  (embeddings): ErnieEmbeddings(\n",
       "    (word_embeddings): Embedding(18000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(513, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): ErnieEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): ErnieLayer(\n",
       "        (attention): ErnieAttention(\n",
       "          (self): ErnieSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ErnieSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ErnieIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): ReLU()\n",
       "        )\n",
       "        (output): ErnieOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): ErniePooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65193067",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '今天天气非常好'\n",
    "enc_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc4589a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.1840e+00, -8.1370e-01, -4.6426e-01,  ...,  2.4156e-01,\n",
       "          -1.5799e+00,  1.0666e-01],\n",
       "         [ 1.1049e+00, -1.1187e-01, -5.4145e-02,  ...,  6.4031e-01,\n",
       "          -1.9835e-02, -3.9115e+00],\n",
       "         [ 1.3144e+00, -1.6369e-01,  4.4185e-01,  ...,  5.9388e-01,\n",
       "          -1.7927e-01, -3.8285e+00],\n",
       "         ...,\n",
       "         [ 1.8316e+00, -1.3574e-01, -2.4131e-01,  ..., -7.9980e-01,\n",
       "           3.7030e-01, -2.7931e+00],\n",
       "         [ 1.1807e+00, -2.3831e-01, -7.9694e-02,  ..., -1.1762e-03,\n",
       "           3.2346e-01, -3.4520e+00],\n",
       "         [ 1.1840e+00, -8.1370e-01, -4.6426e-01,  ...,  2.4156e-01,\n",
       "          -1.5799e+00,  1.0666e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.0000, -1.0000,  0.9998, -0.9993, -0.2206, -1.0000, -0.9985,  0.6936,\n",
       "          0.9843,  0.9521, -1.0000, -0.9861, -0.7171, -1.0000, -0.9649, -0.9533,\n",
       "         -1.0000,  0.9894, -0.7984, -0.3780, -1.0000,  1.0000, -0.8877, -0.5281,\n",
       "         -0.6262,  0.0932, -0.9998,  0.9893,  1.0000,  0.1890, -1.0000,  0.9999,\n",
       "         -1.0000,  0.0135,  1.0000,  0.9804, -1.0000, -0.7823, -0.9359,  0.4366,\n",
       "          0.9979, -0.9771, -0.9996,  0.5026, -0.9776, -0.9946, -1.0000,  1.0000,\n",
       "         -1.0000, -0.8933, -0.7572,  0.9998,  1.0000, -1.0000, -1.0000, -0.9930,\n",
       "          0.7722, -1.0000,  0.9998,  0.8191, -0.9998, -1.0000,  1.0000,  0.8860,\n",
       "          0.0016, -0.9991, -0.4040, -1.0000, -0.9684,  0.9989,  0.9810, -0.9439,\n",
       "         -0.8325, -1.0000,  1.0000, -0.9991, -0.9468,  1.0000,  0.4086,  0.9384,\n",
       "          1.0000,  0.9989, -1.0000,  0.9752,  1.0000, -1.0000, -1.0000,  0.8096,\n",
       "          1.0000,  0.7152, -1.0000,  0.9244,  0.3300,  0.9807,  1.0000, -1.0000,\n",
       "          0.9981, -0.9999,  0.8848,  1.0000,  0.9380,  0.9998, -1.0000,  1.0000,\n",
       "          0.4605, -1.0000,  1.0000, -1.0000,  0.3151, -0.9994, -0.7257,  0.7775,\n",
       "          0.9998,  1.0000,  1.0000, -0.9999, -0.9985, -0.4392,  0.9908,  0.8262,\n",
       "         -0.9997,  1.0000, -0.9999,  0.6132, -1.0000,  0.7395,  0.9996, -0.9994,\n",
       "         -0.9569,  0.8116,  0.9998,  0.9924, -0.9999, -1.0000,  0.9998,  0.9992,\n",
       "          0.9999, -0.9996,  1.0000,  0.8393,  1.0000,  1.0000, -0.5857,  0.9998,\n",
       "          0.9100,  1.0000,  0.9742, -1.0000,  0.0128, -0.6283,  0.9388,  1.0000,\n",
       "          0.4663, -0.9643, -0.9965,  1.0000,  1.0000, -1.0000,  0.9757,  0.9937,\n",
       "          1.0000,  0.9998, -0.9261, -0.9991,  1.0000,  0.9994,  0.4587, -1.0000,\n",
       "          0.9878, -0.7061, -1.0000,  0.9996,  1.0000,  1.0000, -1.0000,  0.8464,\n",
       "          0.6185,  0.5054,  0.8526, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
       "         -0.6709,  0.8814, -0.9999,  0.1961,  0.9241, -1.0000,  0.9862,  0.8218,\n",
       "         -0.9999,  0.9978, -0.9962, -0.9773, -1.0000, -0.9880,  0.3330, -0.9501,\n",
       "          1.0000, -0.3482,  0.9998, -0.9998,  0.8175,  0.9998, -0.9998,  0.9786,\n",
       "          1.0000, -0.9459,  0.2226, -0.9805, -0.1507,  1.0000, -1.0000,  0.7042,\n",
       "          0.9382,  1.0000,  0.9895,  0.0780, -1.0000,  0.9707, -0.9016, -0.9995,\n",
       "         -0.9715, -1.0000, -1.0000,  0.5775,  0.9999,  1.0000,  1.0000, -0.9961,\n",
       "          0.2347,  0.3138, -1.0000, -0.4329, -0.8321,  0.9997, -0.8184,  0.5679,\n",
       "          1.0000, -1.0000,  0.4983,  0.9996, -0.9881, -0.9998, -0.9977,  0.9995,\n",
       "          0.9999, -0.9999, -0.9453,  0.7512,  0.5642,  0.9654,  0.5145,  0.5426,\n",
       "          0.9937,  1.0000, -1.0000, -1.0000, -0.6679,  0.0421, -0.9632, -0.8997,\n",
       "         -0.4620,  1.0000,  1.0000, -0.9937, -1.0000,  0.9878, -0.9952,  1.0000,\n",
       "         -1.0000, -0.7163,  1.0000, -0.9995,  0.9995, -0.9547, -0.5889, -0.9987,\n",
       "          0.9999,  0.9651, -0.9996, -1.0000,  0.9040,  0.9956, -1.0000, -1.0000,\n",
       "         -1.0000,  0.8973,  1.0000,  0.9983,  0.8323,  0.9991,  0.9999,  0.9557,\n",
       "         -0.9919, -0.9999, -1.0000, -1.0000, -0.9508, -0.9626, -0.7920,  0.0284,\n",
       "         -1.0000,  0.8015, -1.0000,  0.9999,  1.0000, -1.0000, -0.7366, -0.9404,\n",
       "          0.9408,  1.0000, -1.0000,  1.0000,  0.8644,  0.9959, -1.0000,  0.9984,\n",
       "         -0.9926,  1.0000, -0.8472, -0.3745,  0.9965, -0.9643, -0.9999,  0.6144,\n",
       "          0.9995, -0.9185, -1.0000,  1.0000, -1.0000,  0.9939, -0.7905,  0.0363,\n",
       "         -0.9997,  0.9656, -0.9847,  0.3305, -1.0000,  0.9974,  1.0000,  0.9898,\n",
       "          0.6775, -1.0000, -0.9995,  1.0000, -0.9983,  0.9076,  0.6007, -0.8108,\n",
       "          0.9037,  1.0000,  0.6781, -1.0000,  0.5639, -0.8863, -0.8957,  0.8422,\n",
       "         -0.9032, -0.9272,  0.3848,  0.9985,  0.9854,  1.0000,  1.0000, -0.9769,\n",
       "         -1.0000,  0.8298,  0.9985, -1.0000, -1.0000, -0.4453,  0.9990,  0.9061,\n",
       "         -0.0829,  0.2423,  0.9651,  0.9989, -1.0000, -0.9999,  1.0000, -0.7322,\n",
       "         -0.9999, -0.9987,  0.9836,  1.0000, -1.0000,  0.9428,  1.0000, -0.9972,\n",
       "         -1.0000, -1.0000,  1.0000,  0.9995,  0.9999,  0.9974, -0.9996,  1.0000,\n",
       "          0.8221, -1.0000, -1.0000,  0.1775, -0.5833, -1.0000, -0.9964, -0.9978,\n",
       "          1.0000,  0.9996, -0.9966,  0.8987,  0.8441, -0.9995,  0.9074,  1.0000,\n",
       "          1.0000, -0.9998, -0.5131, -0.7380,  1.0000, -1.0000,  0.7146,  1.0000,\n",
       "          1.0000, -0.5617, -0.9938, -1.0000, -0.6858, -0.8387, -0.0058,  0.9978,\n",
       "          0.1442,  0.5414,  0.9006,  0.6899,  0.1529,  0.9999,  1.0000, -0.0745,\n",
       "          0.8143, -0.8967,  0.9930,  1.0000,  0.9581,  0.4602, -1.0000,  1.0000,\n",
       "          0.9812, -0.5601, -0.9638, -0.8284,  0.9825, -0.9988,  0.3776,  0.9176,\n",
       "          0.9628,  0.8369, -0.0161, -1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          0.9956,  0.8994, -1.0000, -1.0000, -0.9822, -0.5270, -1.0000, -0.9166,\n",
       "         -0.9973, -0.7608,  0.9989, -1.0000,  0.9999, -1.0000, -0.9698, -0.6508,\n",
       "         -1.0000,  0.8694, -0.9901,  0.9999,  0.9996, -0.9924, -0.1094, -0.9293,\n",
       "          0.8644,  1.0000,  0.9999,  0.9998,  0.3539, -0.0662,  1.0000, -0.9996,\n",
       "         -0.9982,  0.9999,  0.7010, -0.9550, -0.4686,  1.0000,  0.7839, -0.9994,\n",
       "         -1.0000, -0.9972,  0.9832, -1.0000, -0.9016, -0.7408,  0.6258, -1.0000,\n",
       "          0.9627, -1.0000, -0.9480, -0.9997,  0.9885,  1.0000, -1.0000,  1.0000,\n",
       "          0.9987, -0.9316,  0.9796, -0.9984,  0.9285,  1.0000, -0.9995, -1.0000,\n",
       "         -0.8956,  0.0404, -1.0000, -1.0000, -0.9994, -0.9998,  0.9821, -1.0000,\n",
       "         -1.0000,  0.0713, -1.0000,  0.9452,  1.0000,  0.9999,  0.4120,  0.9913,\n",
       "          0.9236,  0.9997,  0.4998,  0.9905, -0.9971,  1.0000, -1.0000, -0.9995,\n",
       "          0.9955, -1.0000, -0.9665,  1.0000, -0.9999, -1.0000,  0.9999,  1.0000,\n",
       "         -0.9999,  0.9899, -0.9967, -0.9249, -1.0000, -0.8976, -0.9862, -1.0000,\n",
       "          0.9973, -0.9865, -1.0000, -0.9999,  1.0000,  0.9634,  0.9990,  0.7950,\n",
       "         -1.0000, -0.9990, -0.1230,  0.8260,  0.9900, -1.0000,  1.0000, -0.9999,\n",
       "          1.0000,  0.4712,  0.9993,  0.9949,  0.9992,  1.0000,  0.9578, -0.7343,\n",
       "         -0.9999,  1.0000, -0.9640, -1.0000,  0.9522, -1.0000, -1.0000,  0.9783,\n",
       "          0.9283,  0.9986, -0.9971, -0.9946, -0.8182, -0.9999,  0.7354, -1.0000,\n",
       "          1.0000,  0.9975, -1.0000, -0.9990, -0.9969, -0.8844,  0.9995, -0.9524,\n",
       "         -0.5782, -1.0000,  0.9997, -1.0000, -0.9813,  0.7535,  0.9983,  0.8348,\n",
       "         -0.9547,  1.0000,  1.0000, -0.9949,  0.9114,  0.1154, -0.0529,  0.9996,\n",
       "          0.7766, -0.9985,  1.0000,  1.0000, -0.9984,  0.9618, -0.5579, -1.0000,\n",
       "         -0.9994,  0.3436,  1.0000, -0.9999, -1.0000,  0.9956, -0.8065, -1.0000,\n",
       "          0.9995, -0.9989,  1.0000,  1.0000, -0.7902, -1.0000,  0.9886,  1.0000,\n",
       "          0.9890,  0.9972,  0.7547,  1.0000,  1.0000, -0.9999, -0.9624,  1.0000,\n",
       "          0.8680,  0.9972,  0.9469, -0.9987,  0.9619,  1.0000,  0.9994,  0.9960,\n",
       "         -0.9934, -1.0000, -0.0896,  0.9655, -0.9942,  1.0000,  1.0000,  0.5006,\n",
       "          0.9999,  0.9149,  0.8914,  0.9197,  1.0000, -0.9996,  0.9982, -0.6982,\n",
       "          0.9307,  1.0000,  0.9994, -0.9961, -0.9924,  0.5901, -0.9908, -0.9987,\n",
       "         -0.4829,  0.7408, -0.9985,  0.9304,  0.9974, -0.3882, -0.9988,  0.9975,\n",
       "         -0.4345, -0.9298,  0.9085,  0.9999,  1.0000, -1.0000, -0.9994,  0.9998,\n",
       "          0.9967,  0.9902,  1.0000,  0.9844, -0.5721, -1.0000,  0.9996, -1.0000,\n",
       "          1.0000, -0.9984, -1.0000,  1.0000,  0.9847,  1.0000,  1.0000,  0.8298,\n",
       "          1.0000,  0.9979, -0.8269,  0.9979, -0.9941, -1.0000,  1.0000,  1.0000,\n",
       "          1.0000, -0.6514,  0.9980, -1.0000, -0.9980,  1.0000, -0.8983,  0.7711,\n",
       "          0.2613, -0.5852,  1.0000,  1.0000, -0.4538,  0.9995,  0.9999,  0.0800,\n",
       "          0.9577,  1.0000,  0.8945, -0.9999,  0.9993,  1.0000,  0.9517,  0.9999,\n",
       "         -0.9480,  0.9879, -0.9435,  1.0000, -0.9998, -0.9976, -0.9993, -0.9997]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d9520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
