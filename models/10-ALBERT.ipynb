{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b79ccc",
   "metadata": {},
   "source": [
    "#### ALBERT：A Lite BERT\n",
    "1.从ALBERT的全称看出，它是一个轻量版的BERT模型。\n",
    "\n",
    "2.embedding矩阵分解，把 V * H 分解成 V * E + E * H，比如E取128，可以降低参数量\n",
    "\n",
    "3.12层的attention层和全连接层层共享参数\n",
    "\n",
    "4.SOP任务替代NSP任务：\n",
    "\n",
    "- SOP任务将负样本换成了同一篇文章中的两个逆序的句子，在预训练时，让模型去预测句子对是正序还是逆序，从而消除topic prediction，让模型学习更难的coherence prediction。实验证明，SOP任务带来的提升比NSP任务要好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ceeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertModel\n",
    "from transformers import AlbertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4dd500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../models/albert-base-v2/ were not used when initializing AlbertModel: ['predictions.LayerNorm.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = '../../models/albert-base-v2/'\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(pretrained_model)\n",
    "model = AlbertModel.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766ad851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertModel(\n",
       "  (embeddings): AlbertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder): AlbertTransformer(\n",
       "    (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "    (albert_layer_groups): ModuleList(\n",
       "      (0): AlbertLayerGroup(\n",
       "        (albert_layers): ModuleList(\n",
       "          (0): AlbertLayer(\n",
       "            (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (attention): AlbertAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (attention_dropout): Dropout(p=0, inplace=False)\n",
       "              (output_dropout): Dropout(p=0, inplace=False)\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (pooler_activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbeac07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "765277d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 1.0633,  0.6634,  1.2338,  ..., -1.5131, -0.4445,  1.2011],\n",
       "         [-0.2914, -0.5385, -1.6138,  ...,  0.2044,  2.1072, -0.3526],\n",
       "         [ 0.3940,  0.8559, -0.5069,  ...,  0.8633,  0.4893,  0.2798],\n",
       "         ...,\n",
       "         [ 0.4754, -1.4797, -0.7564,  ...,  1.2648,  1.6309,  0.4099],\n",
       "         [ 0.0298,  0.1406,  0.2338,  ..., -0.2372,  0.6055, -0.0437],\n",
       "         [ 0.0726,  0.1270, -0.0512,  ..., -0.0985,  0.1229,  0.2115]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.3040e-01,  1.0424e-01,  3.9711e-01, -4.7383e-01, -1.3758e-02,\n",
       "         -9.8533e-01, -5.0131e-02,  1.2261e-02, -5.6495e-02, -9.9441e-01,\n",
       "          9.4768e-01, -1.4119e-01, -5.6679e-01, -8.5202e-01, -8.8070e-01,\n",
       "          2.3836e-01, -1.9595e-01, -1.6009e-01,  9.9556e-01,  6.8593e-02,\n",
       "         -6.8246e-01, -9.9791e-01,  9.9637e-01,  9.3427e-01,  9.4481e-01,\n",
       "          1.9624e-01, -1.2116e-01, -9.9659e-01, -9.5589e-01,  1.7546e-01,\n",
       "         -9.9503e-01, -4.9912e-02, -5.2338e-02, -1.7399e-01, -4.7024e-02,\n",
       "          2.5040e-01,  2.4297e-02,  9.8834e-01,  7.8854e-02, -2.1458e-02,\n",
       "         -2.1279e-01, -9.8895e-01, -6.3510e-01, -2.0707e-01, -2.1754e-01,\n",
       "         -2.9198e-01,  3.6222e-02, -9.9439e-01,  7.4158e-01,  2.8631e-01,\n",
       "          1.9829e-01,  1.4791e-01,  1.1378e-01, -6.8500e-01, -6.1387e-01,\n",
       "         -6.3339e-02,  1.3852e-01,  1.4212e-01,  9.9989e-01, -9.5492e-01,\n",
       "         -5.7282e-02, -4.1079e-02,  6.0181e-02, -6.2924e-01,  1.5933e-01,\n",
       "         -1.6249e-01, -2.6717e-01,  9.9913e-01,  3.4856e-01,  9.7228e-01,\n",
       "         -2.1798e-01,  1.1642e-02, -5.9979e-01,  7.3016e-03,  9.2392e-01,\n",
       "         -9.6833e-02,  8.4510e-01, -1.8919e-01,  7.8178e-01, -9.9320e-01,\n",
       "          4.9023e-01, -5.1956e-02,  2.9479e-02,  1.0081e-01, -7.1091e-01,\n",
       "         -8.9632e-01, -8.5786e-02, -9.9852e-01, -2.4799e-02,  8.0193e-01,\n",
       "         -1.1089e-01,  8.0453e-02,  7.4115e-02, -9.9972e-01, -2.1198e-01,\n",
       "         -5.2243e-02, -9.9954e-01, -1.6375e-01, -1.7113e-01,  8.5360e-02,\n",
       "          6.3804e-01,  1.5071e-01, -6.2199e-02,  1.0385e-01,  7.7855e-02,\n",
       "          2.0418e-01, -6.8647e-02,  9.7039e-01, -2.1730e-01,  9.9775e-01,\n",
       "         -8.0917e-01,  2.9006e-01, -3.2499e-01,  8.8365e-01,  1.2317e-01,\n",
       "          5.1994e-01,  8.1245e-02,  9.3032e-01, -9.9928e-01, -6.9538e-02,\n",
       "         -1.6410e-01,  9.7568e-02, -1.2148e-01, -7.4609e-01, -1.1170e-01,\n",
       "         -1.9996e-01, -2.6327e-01, -6.4652e-01,  9.8205e-01, -8.4030e-01,\n",
       "          8.2175e-01, -2.6660e-01, -9.5082e-01,  4.0787e-01, -1.1160e-01,\n",
       "          9.9751e-01,  1.8755e-01,  3.2216e-01, -5.1529e-02, -1.9900e-02,\n",
       "          9.5602e-01,  8.4380e-02, -2.2763e-01, -1.7339e-02,  1.6868e-01,\n",
       "         -2.1190e-01,  8.8368e-01,  2.4513e-01, -2.8049e-01,  9.9056e-01,\n",
       "         -9.5177e-01,  9.3813e-01,  6.4960e-01,  5.1082e-01, -9.9371e-01,\n",
       "          3.8080e-01,  9.9112e-01, -8.4105e-01,  9.2692e-01,  1.2104e-01,\n",
       "          2.0366e-01, -9.2437e-01, -9.9752e-01,  1.0286e-01, -9.5947e-01,\n",
       "         -7.6835e-02,  9.9712e-01, -6.8112e-01,  8.3198e-01, -9.5980e-01,\n",
       "          3.4711e-01, -2.7769e-01,  1.0016e-01,  9.3410e-01, -2.3233e-01,\n",
       "         -2.4486e-01, -1.0878e-01,  9.2204e-01, -8.8589e-03,  3.4276e-01,\n",
       "          7.8825e-01, -9.9858e-01, -2.2769e-01, -4.8769e-02,  2.1545e-01,\n",
       "         -1.2009e-01, -6.5136e-02, -8.5835e-01, -8.7286e-02, -4.1549e-02,\n",
       "          2.6171e-01, -9.9077e-01, -2.8488e-02,  7.2256e-01,  9.9412e-01,\n",
       "         -1.7670e-01, -1.9144e-01, -9.6841e-01,  9.3920e-01, -9.9170e-01,\n",
       "          4.1565e-03,  9.6685e-01,  9.3978e-01, -1.2539e-01,  5.3476e-03,\n",
       "          9.3723e-01, -9.6679e-01,  4.7938e-01, -9.9658e-01,  2.0717e-01,\n",
       "         -9.9657e-01,  7.7960e-01, -9.9593e-01, -1.7146e-01, -9.7448e-01,\n",
       "          9.9937e-01,  9.3058e-01,  1.3929e-01,  9.1244e-01,  9.5851e-02,\n",
       "          6.8747e-02, -8.1573e-02, -9.9998e-01,  3.0384e-01, -2.2618e-01,\n",
       "         -6.4892e-02,  6.5703e-01,  8.8593e-02,  9.4796e-01, -9.9780e-01,\n",
       "         -9.2430e-01, -5.2151e-01,  7.9665e-02, -6.7506e-01, -8.7814e-01,\n",
       "          1.0003e-01, -1.0749e-01, -7.4753e-02, -2.8733e-02, -9.9971e-01,\n",
       "          9.9923e-01, -1.6980e-01,  2.2332e-01,  9.6405e-02, -6.1845e-01,\n",
       "          9.8297e-01, -7.8360e-02, -8.6407e-01, -2.6640e-02,  9.9739e-01,\n",
       "          9.9426e-01, -5.2484e-02,  5.4557e-03,  1.5402e-01,  4.4536e-01,\n",
       "          2.8992e-01, -9.9268e-01, -9.9930e-01, -9.9597e-01, -1.8221e-01,\n",
       "         -8.8461e-01,  1.4179e-02,  4.0301e-01, -9.9386e-01,  1.3669e-01,\n",
       "          9.5573e-01,  9.9780e-01,  9.7170e-01, -1.1924e-01, -8.5885e-02,\n",
       "         -2.4560e-01,  6.9360e-02,  9.9765e-01, -8.1740e-01,  6.6565e-01,\n",
       "         -9.3592e-01, -9.8520e-01, -9.2749e-02, -1.3484e-01, -2.5550e-01,\n",
       "         -2.0975e-02, -8.6724e-01,  3.5678e-02, -5.2313e-02,  9.8861e-01,\n",
       "         -9.3719e-01,  8.7973e-01, -8.6758e-01, -9.9509e-01, -1.7937e-01,\n",
       "          5.2549e-02, -3.7438e-03,  9.9190e-01,  2.2331e-01, -9.9869e-01,\n",
       "         -9.3823e-01,  4.6489e-01,  9.2864e-01,  3.9182e-01, -9.9488e-01,\n",
       "         -1.9102e-01,  1.0388e-01, -8.0936e-03,  9.9682e-01, -1.6855e-01,\n",
       "          2.7679e-01,  3.0604e-01, -7.3694e-02, -2.4646e-01,  9.2795e-01,\n",
       "         -9.1661e-01,  1.1272e-01, -8.5794e-01, -2.4332e-01,  2.1810e-01,\n",
       "         -8.8934e-01,  2.1975e-01, -8.0795e-01,  7.1513e-01,  9.6914e-01,\n",
       "          1.8955e-01, -7.8793e-02,  9.9655e-01, -9.9800e-01,  8.2725e-03,\n",
       "         -9.6072e-01,  9.1349e-01, -9.5742e-01, -9.8602e-01, -3.1262e-01,\n",
       "         -7.8506e-01,  1.7597e-01, -1.0734e-02, -9.3480e-01, -2.2196e-01,\n",
       "         -9.9489e-01, -1.8864e-01,  8.3311e-02,  9.4341e-01,  9.1731e-01,\n",
       "         -9.8354e-01,  1.8452e-01, -9.4208e-01, -2.0079e-01,  8.8149e-02,\n",
       "         -1.9714e-01,  5.7268e-01, -5.4982e-02,  8.9439e-03, -9.9879e-01,\n",
       "         -1.7795e-01,  8.2119e-01,  2.1595e-02,  8.6678e-01,  5.3191e-02,\n",
       "         -1.0110e-01, -8.0046e-01, -7.3905e-01,  2.8800e-01,  9.8988e-01,\n",
       "          9.0597e-01, -5.6623e-01,  2.6335e-01, -1.0306e-01, -3.3526e-01,\n",
       "          9.9869e-01, -9.7301e-01,  9.9492e-01, -9.4553e-01,  1.3357e-01,\n",
       "         -9.9363e-01,  9.7325e-01,  8.8394e-01,  8.2483e-01,  1.5882e-02,\n",
       "         -6.4678e-01, -9.9092e-01, -4.2763e-02,  1.9504e-01,  2.5421e-01,\n",
       "          7.2128e-02,  9.6918e-01, -2.1326e-01,  9.1057e-01, -9.6023e-01,\n",
       "          3.9495e-01, -2.8381e-01,  9.0247e-01, -9.1458e-01,  9.9940e-01,\n",
       "         -9.2819e-01,  1.3806e-01, -7.8345e-01,  9.9988e-01,  6.9718e-02,\n",
       "         -1.8318e-01, -9.8927e-01, -8.3768e-01,  8.0201e-02, -2.6761e-01,\n",
       "          9.6231e-01,  1.3731e-01, -7.1935e-01,  9.0147e-01,  9.8725e-01,\n",
       "         -9.9234e-01, -8.5953e-02,  9.8630e-01,  4.6050e-01, -4.2922e-03,\n",
       "          1.2314e-01,  1.8170e-02,  7.6867e-01, -7.0130e-02,  9.8951e-01,\n",
       "          1.2075e-01,  9.7611e-01, -9.9897e-01, -9.9830e-01,  8.1365e-01,\n",
       "          1.5328e-01,  9.8608e-01,  6.9809e-02, -1.1681e-01, -2.6997e-01,\n",
       "          1.6115e-02,  4.1885e-02,  1.9147e-01, -2.1898e-01,  8.1055e-01,\n",
       "          4.6623e-02,  9.9253e-01, -3.6798e-01, -9.9428e-01, -9.9023e-01,\n",
       "          2.7282e-02,  2.5764e-03,  4.0158e-02,  1.9896e-01,  9.6002e-01,\n",
       "          1.3095e-01, -8.9153e-01, -2.5746e-02,  4.2799e-03, -1.2539e-01,\n",
       "         -8.1178e-01,  9.9654e-01, -9.9204e-01,  7.1752e-01,  1.0877e-01,\n",
       "         -8.1735e-01,  7.7196e-01,  8.5298e-01,  1.2152e-01, -9.8694e-01,\n",
       "          8.0595e-02, -9.6307e-01, -2.1875e-05,  1.8762e-01, -9.7350e-01,\n",
       "          1.1438e-01,  7.7677e-01,  1.0459e-01,  9.9229e-01,  6.0646e-01,\n",
       "         -2.6780e-02, -9.2754e-01,  9.9997e-01, -8.7929e-01, -9.9954e-01,\n",
       "         -1.6270e-01, -1.5951e-01,  2.7264e-01, -2.0389e-01, -3.0113e-01,\n",
       "         -1.7844e-01, -8.0561e-01,  1.2145e-01,  9.8868e-01, -9.4858e-01,\n",
       "          1.1353e-01, -9.9623e-01,  9.9868e-01, -2.3344e-02, -8.3782e-01,\n",
       "          9.3409e-01,  9.8557e-01,  9.8938e-01,  5.7522e-02, -9.9476e-01,\n",
       "         -3.3060e-02, -9.3644e-01, -9.9435e-01, -8.1909e-02, -9.7548e-01,\n",
       "          9.4893e-01, -1.0676e-01,  1.9106e-01,  9.2662e-01,  8.7443e-01,\n",
       "          2.7110e-01,  1.7568e-01, -9.6380e-01, -9.6451e-01,  2.4716e-01,\n",
       "         -8.9801e-01, -1.0089e-01, -9.9962e-01, -8.5845e-01, -9.0564e-01,\n",
       "         -9.9377e-01, -2.4379e-01, -9.5094e-01, -1.2884e-01, -9.8153e-01,\n",
       "          1.5932e-01,  7.6847e-02, -1.7707e-01,  2.3749e-01, -1.2751e-01,\n",
       "         -1.3370e-01,  1.7868e-01, -2.8548e-01,  9.9736e-01,  1.8111e-01,\n",
       "          9.9730e-01,  9.9030e-01,  9.7614e-01, -1.9741e-01, -8.9286e-01,\n",
       "          1.8896e-01,  9.6889e-01, -5.8823e-01, -7.2168e-01,  6.8454e-01,\n",
       "         -9.9668e-01,  6.7636e-01, -8.1214e-01,  8.4033e-01, -3.3455e-01,\n",
       "         -9.0599e-01, -9.3052e-01,  1.1943e-01, -9.9994e-01, -8.9491e-01,\n",
       "         -9.6641e-01, -1.2389e-01,  9.2887e-01, -9.9283e-01,  9.9151e-01,\n",
       "          4.4437e-02, -8.6406e-01,  9.6787e-01,  2.3231e-02, -9.8346e-01,\n",
       "         -1.8052e-01,  1.5202e-01,  9.9728e-01,  2.8673e-01,  9.9235e-01,\n",
       "          5.4325e-02, -9.8034e-01,  9.6542e-01,  7.1250e-01,  1.8919e-01,\n",
       "          9.1966e-02, -4.9665e-01, -9.6901e-01,  8.7764e-01,  2.8738e-01,\n",
       "          1.7140e-02,  9.6889e-01, -6.6511e-01, -9.4274e-02,  6.9736e-02,\n",
       "         -1.9111e-01, -9.9670e-01, -2.0449e-01, -9.7285e-01, -3.2913e-01,\n",
       "         -9.9269e-01, -9.3664e-01,  9.8493e-01, -1.4493e-01, -7.4315e-02,\n",
       "         -1.4385e-01, -5.6965e-02,  3.4197e-01,  8.8605e-01, -9.8582e-01,\n",
       "          2.2948e-01, -1.3791e-01, -6.5163e-01,  4.4890e-01,  1.5442e-01,\n",
       "          3.9280e-02, -1.5688e-01,  9.9702e-01,  3.1549e-01,  3.6276e-01,\n",
       "         -6.4496e-02,  4.9821e-02, -8.6314e-02, -7.6554e-02, -1.8607e-01,\n",
       "          8.1279e-01, -8.0227e-02, -8.8221e-01,  1.4556e-01,  2.3963e-01,\n",
       "          1.9192e-01,  9.4473e-01,  9.9943e-01, -1.5802e-02, -2.6156e-01,\n",
       "          1.8460e-01, -9.8726e-01,  9.6216e-01,  2.0181e-01,  9.9235e-01,\n",
       "          9.9628e-01,  1.2431e-01,  2.6691e-01, -4.8454e-01,  9.9948e-01,\n",
       "          9.8428e-01,  1.5864e-02,  8.8658e-01, -1.2680e-01,  4.9018e-02,\n",
       "          8.8171e-02,  9.8536e-01, -9.2226e-01,  5.9000e-01, -5.2169e-02,\n",
       "          4.9463e-01,  9.5426e-01,  7.8304e-02,  9.0998e-01, -9.9902e-01,\n",
       "          2.7999e-01,  9.4103e-01, -9.9615e-01, -7.6391e-02,  9.8373e-01,\n",
       "         -9.9719e-01,  2.0421e-01,  1.0913e-01,  9.6795e-01, -1.8612e-02,\n",
       "         -1.6616e-01, -1.5763e-01,  3.0080e-01,  1.1461e-01,  9.9956e-01,\n",
       "         -2.4178e-01,  1.3591e-01,  9.9811e-01,  1.4802e-01,  2.7473e-01,\n",
       "         -8.0483e-02,  1.1487e-02,  9.9804e-01,  9.7819e-01, -9.7063e-01,\n",
       "          1.9274e-01, -2.4003e-01, -1.0820e-01,  9.9942e-01, -9.9841e-01,\n",
       "          1.5901e-01, -3.2751e-01, -6.7844e-01, -1.5671e-01,  9.1314e-01,\n",
       "          1.9292e-02,  2.0958e-02, -9.9940e-01, -2.8717e-02,  9.4031e-01,\n",
       "         -6.0923e-02,  9.9548e-01, -1.5843e-01, -2.5460e-01,  6.0510e-01,\n",
       "          7.8539e-01,  3.0462e-01,  8.9446e-01, -9.3100e-01, -1.5987e-01,\n",
       "         -3.9562e-01, -1.1335e-01,  1.0113e-01, -8.1846e-01, -1.2628e-02,\n",
       "         -3.6632e-02,  8.6863e-01, -7.2836e-02, -2.4185e-01, -9.5374e-01,\n",
       "          5.3153e-02, -7.8555e-02, -1.7119e-01, -2.3549e-01,  1.9469e-01,\n",
       "          1.1125e-01,  1.5572e-01, -9.3611e-01, -5.4279e-01, -1.7163e-01,\n",
       "         -3.6062e-01, -4.8281e-02,  1.6014e-01, -9.6124e-01, -1.2670e-01,\n",
       "          1.3828e-01, -1.6065e-02, -9.8009e-01, -9.6805e-01,  1.2154e-01,\n",
       "         -8.5674e-01,  1.3435e-01, -1.6827e-01,  1.2826e-01, -1.2779e-01,\n",
       "         -6.6942e-01, -1.0000e+00, -4.0340e-01, -2.2260e-01, -7.0546e-01,\n",
       "         -1.6767e-01, -5.5096e-01, -2.1272e-01,  9.9983e-01,  1.0000e+00,\n",
       "         -9.7035e-01, -1.1583e-01, -9.7028e-01,  2.2730e-01, -2.0396e-02,\n",
       "         -9.9602e-01, -2.5706e-01,  9.9988e-01,  1.9010e-02, -2.2819e-01,\n",
       "         -9.9888e-01, -8.0973e-01,  9.8552e-01, -7.5838e-01, -8.5575e-02,\n",
       "         -1.5278e-01,  2.3182e-01, -9.9073e-01, -5.2722e-01, -8.2800e-02,\n",
       "         -5.8641e-03, -6.8183e-02, -9.9694e-01, -3.2905e-02, -9.6240e-02,\n",
       "         -9.9885e-01, -3.2426e-01,  9.3074e-01,  2.4958e-01, -1.5258e-01,\n",
       "          4.7611e-01, -5.2418e-01, -3.9122e-02]], grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e93e484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3715081512928009,\n",
       "  'token': 1380,\n",
       "  'token_str': 'meant',\n",
       "  'sequence': 'spacy is meant to help you do real work  to build real products,'},\n",
       " {'score': 0.21246449649333954,\n",
       "  'token': 2293,\n",
       "  'token_str': 'supposed',\n",
       "  'sequence': 'spacy is supposed to help you do real work  to build real products,'},\n",
       " {'score': 0.027506107464432716,\n",
       "  'token': 1006,\n",
       "  'token_str': 'designed',\n",
       "  'sequence': 'spacy is designed to help you do real work  to build real products,'},\n",
       " {'score': 0.01515924371778965,\n",
       "  'token': 301,\n",
       "  'token_str': 'something',\n",
       "  'sequence': 'spacy is something to help you do real work  to build real products,'},\n",
       " {'score': 0.013648479245603085,\n",
       "  'token': 677,\n",
       "  'token_str': 'done',\n",
       "  'sequence': 'spacy is done to help you do real work  to build real products,'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model=pretrained_model)\n",
    "unmasker(\"spaCy is [MASK] to help you do real work — to build real products,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0af60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
