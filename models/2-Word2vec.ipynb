{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad062b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1faf6d2",
   "metadata": {},
   "source": [
    "# 1.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb169b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path, stopwords, sample=None):\n",
    "        df = pd.read_csv(file_path).dropna().reset_index(drop=True)\n",
    "        if sample:\n",
    "            df = df.sample(sample).reset_index(drop=True)\n",
    "\n",
    "        counter = Counter()\n",
    "        sentences = []\n",
    "        \n",
    "        for title in tqdm(df['title']):   \n",
    "            # 去除标点符号\n",
    "            title = re.sub(r'[^\\u4e00-\\u9fa5]', '', title)\n",
    "            tokens = [token for token in jieba.cut(title.strip()) if token not in stopwords]\n",
    "            counter.update(tokens)\n",
    "            sentences.append(tokens)\n",
    "        self.vocab = torchtext.vocab.vocab(counter, specials=['<unk>', '<pad>'])\n",
    "        \n",
    "        # 构造输入和输出，跳元模型，用当前字预测前一个字和后一个字\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        for sen in sentences:\n",
    "            for i in range(1, len(sen) - 1):\n",
    "                self.inputs.append([self.vocab[sen[i]]])\n",
    "                self.labels.append([self.vocab[sen[i - 1]]])\n",
    "                self.inputs.append([self.vocab[sen[i]]])\n",
    "                self.labels.append([self.vocab[sen[i + 1]]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.inputs[idx]), torch.LongTensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fa1387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a948e037f1f43ebba12ce72cf467680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = '../../datasets/THUCNews/train.csv'\n",
    "stopwords = [line.strip() for line in open('../stopwords/cn_stopwords.txt', 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "dataset = MyDataset(file_path, stopwords, sample=1000)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4eb3e5",
   "metadata": {},
   "source": [
    "# 2.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d651b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        # W和WT的形状是转置的\n",
    "        self.W = nn.Embedding(vocab_size, embed_size)  # vocab_size -> embed_size\n",
    "        self.WT = nn.Linear(embed_size, vocab_size, bias=False)  # embed_size -> vocab_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X形状：batch_size * vocab_size\n",
    "        hidden_layer = self.W(X)\n",
    "        output_layer = self.WT(hidden_layer)\n",
    "        return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71631957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(\n",
      "  (W): Embedding(5000, 512)\n",
      "  (WT): Linear(in_features=512, out_features=5000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = Word2Vec(vocab_size=len(dataset.vocab), embed_size=512)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 查看模型\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f7c0d",
   "metadata": {},
   "source": [
    "# 3.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edadaac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss = 8.514538\n",
      "epoch: 2 loss = 6.321123\n",
      "epoch: 3 loss = 4.709826\n",
      "epoch: 4 loss = 3.780671\n",
      "epoch: 5 loss = 3.456005\n",
      "epoch: 6 loss = 3.442016\n",
      "epoch: 7 loss = 3.048970\n",
      "epoch: 8 loss = 3.067402\n",
      "epoch: 9 loss = 3.020471\n",
      "epoch: 10 loss = 2.988716\n",
      "epoch: 11 loss = 2.834623\n",
      "epoch: 12 loss = 2.975353\n",
      "epoch: 13 loss = 2.804723\n",
      "epoch: 14 loss = 2.660689\n",
      "epoch: 15 loss = 2.793330\n",
      "epoch: 16 loss = 3.006624\n",
      "epoch: 17 loss = 2.877311\n",
      "epoch: 18 loss = 2.860091\n",
      "epoch: 19 loss = 2.853536\n",
      "epoch: 20 loss = 2.676005\n"
     ]
    }
   ],
   "source": [
    "# 训练20个epoch\n",
    "for epoch in range(20):\n",
    "    for train_input, train_label in dataloader:\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output.squeeze_(), train_label.squeeze_())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch:', epoch + 1, 'loss =', '{:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2426e0d",
   "metadata": {},
   "source": [
    "# 4.查看模型参数（vector）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee9ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, WT = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55f9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 512]) torch.Size([5000, 512])\n"
     ]
    }
   ],
   "source": [
    "# W对应vocab中每个词的vector，这里是512维\n",
    "print(W.shape, WT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d630e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9.7986e-02,  8.0324e-01, -2.6938e-01,  1.2315e-01,  6.8222e-01,\n",
      "        -1.6469e+00, -1.0018e+00, -1.1281e-01, -1.1169e+00,  5.1680e-01,\n",
      "         2.8906e-02, -1.0431e+00,  8.9166e-01, -1.1216e+00,  1.3011e+00,\n",
      "        -9.1865e-01, -1.7741e-01, -2.0525e-01,  7.3771e-01, -4.9387e-01,\n",
      "        -1.1042e-01, -1.8730e+00,  5.6812e-01, -8.4762e-02,  1.8729e-01,\n",
      "         8.0230e-01, -7.0468e-01,  7.1599e-01,  1.2728e+00,  4.8130e-01,\n",
      "         5.6721e-01, -5.9125e-01, -1.3044e+00,  2.2909e+00,  3.2052e-01,\n",
      "         2.5068e-01,  7.1812e-01, -1.2433e-01, -4.7760e-01, -4.6170e-01,\n",
      "        -4.7226e-03,  4.7565e-01,  1.7193e+00,  1.2292e+00,  2.3644e+00,\n",
      "        -9.8047e-01, -1.4936e+00, -4.0834e-01,  1.4220e-01, -3.2324e-01,\n",
      "         6.9451e-03,  4.4440e-01, -1.0876e+00,  1.3307e+00,  5.3569e-01,\n",
      "        -1.4927e+00, -5.8807e-01, -2.5607e+00, -1.2350e+00,  6.2898e-01,\n",
      "        -4.7516e-01,  5.9551e-01, -3.9008e-01,  1.0815e+00,  1.7505e-01,\n",
      "         1.5820e+00, -2.7845e+00,  2.0758e-01,  1.4120e+00,  1.7098e-01,\n",
      "         6.2063e-01, -7.1049e-01,  2.5872e-01,  6.8199e-02, -1.1021e-02,\n",
      "         5.0930e-01, -5.0668e-01,  1.1406e-01, -3.3006e-01, -9.8143e-01,\n",
      "        -9.1589e-01, -1.8670e-01, -7.5680e-01, -1.3636e+00, -7.4044e-01,\n",
      "         3.5521e-01, -1.4118e+00,  7.9725e-01,  4.0926e-01,  6.2662e-01,\n",
      "        -2.1651e-02,  8.0516e-01,  1.3751e+00, -7.1983e-01, -7.3982e-01,\n",
      "         3.1485e-01, -1.1012e+00,  7.8450e-01,  1.5744e+00, -7.0052e-01,\n",
      "        -6.5866e-01, -3.7853e-01, -2.5293e+00,  8.1051e-01, -9.1194e-02,\n",
      "        -1.2090e+00, -1.2644e-01,  2.1148e-01, -1.4132e-01, -2.0826e+00,\n",
      "        -7.6148e-01,  3.0479e-01,  9.4774e-02, -1.4165e-01, -1.6251e+00,\n",
      "        -4.3678e-01, -1.3703e+00,  6.9910e-01,  1.3609e-03,  4.8106e-01,\n",
      "         6.0012e-01,  8.4634e-01,  1.6704e+00,  9.6806e-01,  1.0076e+00,\n",
      "         2.3599e+00, -1.0810e+00,  8.5684e-01,  1.2698e+00, -1.7124e-01,\n",
      "        -8.6251e-01, -7.4049e-01,  1.4821e+00,  9.9383e-01,  2.2935e-01,\n",
      "         3.4706e-01,  2.0151e-01,  8.2821e-01, -9.7165e-01,  4.7922e-01,\n",
      "        -3.6433e-02,  9.5138e-01, -5.2920e-01,  1.6375e+00, -1.0577e+00,\n",
      "        -6.5688e-01,  6.5716e-01,  6.6640e-01, -3.9498e-01,  7.7377e-01,\n",
      "        -2.2239e-02,  5.8312e-01, -4.0900e-01,  1.0242e+00,  1.5757e-01,\n",
      "         6.1485e-01, -1.0832e+00, -6.5986e-01,  5.3605e-01,  6.9718e-01,\n",
      "        -5.0130e-01,  5.9820e-02,  6.5322e-01, -1.3692e+00, -3.0213e-01,\n",
      "        -6.4190e-02, -3.2202e-01, -1.0398e+00, -1.9565e+00, -8.5988e-01,\n",
      "        -9.8947e-01, -1.3000e+00, -6.5864e-01, -5.7243e-01,  1.3699e+00,\n",
      "         5.3800e-01,  1.0891e-01,  4.4359e-01,  5.5217e-01,  8.3421e-02,\n",
      "         1.0069e-01,  1.5351e+00, -5.7187e-01, -7.9447e-01,  7.5568e-01,\n",
      "         2.2547e-01,  4.8582e-01, -1.0706e+00,  6.0021e-01,  5.6258e-02,\n",
      "         1.8779e+00, -7.1243e-01, -2.8528e-01,  1.3878e+00, -4.6010e-01,\n",
      "        -4.4966e-01,  1.0412e+00,  1.6866e-01,  2.2368e-01, -1.0863e+00,\n",
      "         1.0218e+00, -4.8508e-01,  3.9359e-01,  7.5698e-01, -7.0700e-01,\n",
      "        -1.4158e+00,  5.3704e-02, -2.5528e+00, -3.2452e-01,  8.0378e-01,\n",
      "         2.3804e-01, -1.2600e+00,  2.4434e+00,  8.8422e-01, -1.0849e+00,\n",
      "         4.9313e-02,  9.6018e-01, -6.2264e-01, -2.4428e-01, -1.1192e+00,\n",
      "         1.7461e+00,  2.4320e+00, -7.4957e-02,  8.1327e-01, -1.2982e+00,\n",
      "         6.8804e-01, -9.4375e-01, -6.4609e-01,  1.7163e-01, -2.8027e-01,\n",
      "        -8.8074e-01,  2.7513e-01, -1.1087e+00,  2.3345e-01, -6.8516e-02,\n",
      "         1.0292e+00, -2.1728e+00, -1.0567e+00, -1.1866e+00, -7.4948e-02,\n",
      "        -1.8812e-01, -1.0765e+00, -6.6247e-01, -1.4952e+00, -2.6477e-01,\n",
      "        -2.9202e-02,  2.2685e-01, -1.6905e+00, -1.1586e-01, -1.9466e+00,\n",
      "         1.1617e+00,  1.4261e+00, -5.7827e-01,  3.5681e-01,  5.9546e-01,\n",
      "        -1.5500e+00,  3.1381e-01, -4.2590e-01, -2.1944e-01,  4.7718e-01,\n",
      "        -7.3233e-01, -1.2598e+00,  2.5270e+00, -2.5407e-01, -1.3956e+00,\n",
      "         2.5289e+00, -8.3186e-01, -1.8443e-01,  1.4344e+00,  4.4296e-01,\n",
      "         3.1802e-01,  1.6158e-01, -1.3186e+00,  7.8802e-01, -1.5210e+00,\n",
      "        -4.1218e-01,  1.2571e+00,  6.4467e-02, -2.1243e-01, -6.6669e-01,\n",
      "         8.8925e-01,  6.8138e-01, -4.3664e-02, -7.3500e-01, -2.2005e+00,\n",
      "         2.3460e-01, -7.5435e-01,  1.5693e+00, -6.9587e-01, -3.4432e-01,\n",
      "        -4.3713e-01, -6.1884e-01, -1.9120e+00,  8.5679e-01,  1.1571e-01,\n",
      "         9.0455e-01, -1.6363e+00, -5.7879e-01, -2.1653e+00, -6.7229e-02,\n",
      "         8.0169e-02,  5.4222e-01,  8.9690e-02,  6.7707e-01,  9.6477e-01,\n",
      "         5.2578e-02, -4.9921e-01, -7.3962e-01,  2.2299e-01, -1.2039e-01,\n",
      "         1.0178e-01, -7.9859e-01, -5.0211e-01,  3.8723e-01,  8.3758e-01,\n",
      "         6.7479e-02, -1.7151e+00,  3.0834e-02, -1.2928e+00,  5.3917e-01,\n",
      "         7.1775e-01, -6.0586e-01, -1.6007e-01, -6.2755e-01, -3.0653e-02,\n",
      "         1.6633e+00,  5.8306e-02, -2.9519e-01,  4.4551e-01,  6.8027e-01,\n",
      "        -7.0866e-01, -1.2806e-01, -1.1063e+00,  1.6070e-01, -1.1254e-01,\n",
      "        -6.6748e-01, -1.2266e+00, -1.3342e+00,  1.0621e+00,  9.1125e-01,\n",
      "        -1.2409e+00, -2.2653e-01, -9.4618e-01, -9.8530e-01, -3.4712e-01,\n",
      "        -4.1482e-01, -2.6453e-01,  2.1176e+00,  1.8182e+00,  6.3672e-01,\n",
      "        -3.9993e-01,  8.2367e-01,  4.9758e-01, -8.8030e-01,  1.5953e+00,\n",
      "        -1.3317e+00, -2.9111e-01,  2.7553e-01, -7.1236e-02,  1.6880e-01,\n",
      "         1.1935e+00, -5.0392e-01,  2.8993e-01, -5.1537e-01,  2.6910e-01,\n",
      "        -1.0477e+00, -1.2154e-01,  1.3650e-01, -1.4567e-01, -4.3258e-01,\n",
      "        -3.7898e-01, -9.4385e-01,  5.3011e-01,  7.0219e-01, -8.7441e-01,\n",
      "        -1.2289e+00, -9.9531e-01, -1.5213e+00, -7.6170e-01,  7.5803e-01,\n",
      "        -9.0045e-01,  1.0189e+00,  7.8017e-02, -3.4083e-01,  1.5722e-01,\n",
      "        -2.5473e-01,  8.2319e-01,  1.9949e+00,  1.0313e+00, -3.8584e-01,\n",
      "        -1.6495e+00, -1.5336e+00,  1.3867e-01,  1.5599e+00,  2.2837e-01,\n",
      "        -1.5775e+00,  1.0422e+00,  1.7735e-01,  7.0511e-01, -2.5583e-01,\n",
      "         1.7058e+00, -2.5306e-01,  4.1199e-01, -1.2668e+00, -2.3823e-01,\n",
      "         5.7004e-01, -1.4522e+00,  1.3372e+00, -8.2780e-01,  1.1910e+00,\n",
      "         2.3740e+00,  8.6323e-02, -2.3316e-01,  1.6897e+00,  1.2761e+00,\n",
      "        -6.1762e-04,  2.0659e+00,  5.7566e-01,  7.2848e-01,  5.1575e-01,\n",
      "         3.6924e-01, -4.6477e-01, -1.6448e-02, -5.0564e-01, -8.1375e-01,\n",
      "         7.1689e-01,  9.3365e-01, -1.2739e+00,  2.8507e-01, -4.1257e-01,\n",
      "        -2.7922e-02,  2.8234e-02, -1.1037e+00,  1.6407e+00,  6.7938e-01,\n",
      "         4.1580e-01, -2.3309e-01, -9.9501e-01,  8.5440e-01, -1.4172e+00,\n",
      "        -2.4377e-01,  1.8282e+00,  6.5802e-01,  4.4678e-01, -8.0355e-01,\n",
      "        -3.2886e-02, -9.8308e-02,  3.3805e-01,  1.1514e+00,  1.5844e+00,\n",
      "        -2.4293e+00,  9.1261e-02, -5.0242e-01,  4.8281e-02,  1.4411e+00,\n",
      "        -4.6150e-02,  6.8123e-02, -1.1039e+00, -9.4939e-01,  5.0732e-01,\n",
      "        -4.6534e-01, -1.2138e+00, -7.2047e-01,  7.3303e-01,  2.3911e-01,\n",
      "        -1.8059e+00,  3.3696e-01,  6.1449e-01, -1.8767e+00, -1.1371e+00,\n",
      "        -1.5131e+00,  9.1235e-01,  1.3762e+00,  4.2113e-01, -7.8844e-01,\n",
      "         1.2953e+00, -1.5353e+00, -6.4229e-01,  6.0884e-01, -6.3087e-01,\n",
      "        -2.7950e-01, -8.5044e-01,  7.1231e-01, -1.1594e+00, -1.6358e+00,\n",
      "         1.9397e+00,  1.8386e-02,  8.5415e-01,  1.1099e-01,  7.6117e-02,\n",
      "         2.5581e-01,  1.0121e+00,  3.0057e-01, -1.2666e+00,  8.9326e-01,\n",
      "         4.6592e-01, -9.4308e-01,  3.5603e-01,  7.0730e-01,  1.2546e+00,\n",
      "        -2.7754e+00,  2.3798e-01,  7.2767e-02,  1.0847e+00, -6.5088e-01,\n",
      "         1.3688e-01,  7.0408e-01, -1.0671e+00,  1.6303e-01,  2.0443e-01,\n",
      "        -5.1082e-01,  2.3408e-01], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2e48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
